{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdbff96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c703a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-29 11:34:50,691 INFO: Initializing external client\n",
      "2025-12-29 11:34:50,692 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-12-29 11:34:52,318 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267871\n",
      "Successfully connected to Feature Store: a1id2223_featurestore\n",
      "HSFS Version: 4.2.10\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "# 1. Login\n",
    "project = hopsworks.login()\n",
    "\n",
    "# 2. Get the Feature Store (This triggers the metadata check)\n",
    "try:\n",
    "    fs = project.get_feature_store(\"A1ID2223\")\n",
    "    print(f\"Successfully connected to Feature Store: {fs.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature Store Connection Error: {e}\")\n",
    "\n",
    "# 3. Check versions\n",
    "print(f\"HSFS Version: {hsfs.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eebc363",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/sambarati/Documents/GitHub/nlp-stock-prediction/data/apple_news_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e59c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment data: 1574 rows, 1574 unique dates\n",
      "sentiment_polarity    0.994\n",
      "sentiment_neg         0.023\n",
      "sentiment_neu         0.869\n",
      "sentiment_pos         0.108\n",
      "Name: 2016-02-19 00:00:00+00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sentiment data by date\n",
    "# Convert date column to datetime first\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "# Normalize to date only (remove time component)\n",
    "data['date'] = data['date'].dt.normalize()\n",
    "\n",
    "# Since we may have multiple news articles per day, calculate daily averages\n",
    "sentiment_daily = data.groupby('date').agg({\n",
    "    'sentiment_polarity': 'mean',\n",
    "    'sentiment_neg': 'mean',\n",
    "    'sentiment_neu': 'mean',\n",
    "    'sentiment_pos': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Get smallest and highest dates\n",
    "from_date = sentiment_daily['date'].min()\n",
    "# Set index to date for later join\n",
    "sentiment_daily.set_index('date', inplace=True)\n",
    "\n",
    "print(f\"Sentiment data: {len(sentiment_daily)} rows, {sentiment_daily.index.nunique()} unique dates\")\n",
    "print(sentiment_daily.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94019253",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = yf.Ticker(\"AAPL\") \n",
    "\n",
    "# for news in stock_data.news:\n",
    "#     print(news['content']['summary'])\n",
    "\n",
    "stock_data_price_history = stock_data.history(period=\"10y\") # Get 10 yr price history\n",
    "stock_data_clean = stock_data_price_history[['Open']] # 'High', 'Low', 'Close', 'Volume', 'Open'\n",
    "stock_data_clean = stock_data_clean[from_date:]\n",
    "\n",
    "# Create next-day target from today's open\n",
    "stock_data_clean[\"target_open\"] = stock_data_clean[\"Open\"].shift(-1)\n",
    "# Drop last row without a next-day target\n",
    "stock_data_clean = stock_data_clean.dropna(subset=[\"target_open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cddccecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-02-19 05:00:00', '2016-02-22 05:00:00',\n",
      "               '2016-02-23 05:00:00', '2016-02-24 05:00:00',\n",
      "               '2016-02-25 05:00:00', '2016-02-26 05:00:00',\n",
      "               '2016-02-29 05:00:00', '2016-03-01 05:00:00',\n",
      "               '2016-03-02 05:00:00', '2016-03-03 05:00:00',\n",
      "               ...\n",
      "               '2025-12-11 05:00:00', '2025-12-12 05:00:00',\n",
      "               '2025-12-15 05:00:00', '2025-12-16 05:00:00',\n",
      "               '2025-12-17 05:00:00', '2025-12-18 05:00:00',\n",
      "               '2025-12-19 05:00:00', '2025-12-22 05:00:00',\n",
      "               '2025-12-23 05:00:00', '2025-12-24 05:00:00'],\n",
      "              dtype='datetime64[ns]', name='Date', length=2478, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Remove timezone from stock data to match sentiment data (which is timezone-naive)\n",
    "stock_data_clean.index = stock_data_clean.index.tz_convert(None)\n",
    "print(stock_data_clean.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37cc91d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock tz: None, Sentiment tz: None\n",
      "Sentiment index sample: DatetimeIndex(['2016-02-19', '2017-10-05', '2017-11-27', '2017-11-30',\n",
      "               '2018-01-31'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Remove timezone from sentiment data to match stock data (which is timezone-naive)\n",
    "sentiment_daily.index = sentiment_daily.index.tz_localize(None)\n",
    "print(f\"Stock tz: {stock_data_clean.index.tz}, Sentiment tz: {sentiment_daily.index.tz}\")\n",
    "print(f\"Sentiment index sample: {sentiment_daily.index[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c6888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock dates: DatetimeIndex(['2016-02-19', '2016-02-22', '2016-02-23', '2016-02-24',\n",
      "               '2016-02-25'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n",
      "Sentiment dates: DatetimeIndex(['2016-02-19', '2017-10-05', '2017-11-27', '2017-11-30',\n",
      "               '2018-01-31'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n",
      "\n",
      "Stock data has 0 duplicate dates\n",
      "Sentiment data has 0 duplicate dates\n"
     ]
    }
   ],
   "source": [
    "# Normalize stock data index to date only (remove time component)\n",
    "stock_data_clean.index = stock_data_clean.index.normalize()\n",
    "# Sentiment data is already normalized\n",
    "\n",
    "# Rename both indices to 'date' (lowercase) for consistency\n",
    "stock_data_clean.index.name = 'date'\n",
    "sentiment_daily.index.name = 'date'\n",
    "\n",
    "print(f\"Stock dates: {stock_data_clean.index[:5]}\")\n",
    "print(f\"Sentiment dates: {sentiment_daily.index[:5]}\")\n",
    "print(f\"\\nStock data has {stock_data_clean.index.duplicated().sum()} duplicate dates\")\n",
    "print(f\"Sentiment data has {sentiment_daily.index.duplicated().sum()} duplicate dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7dfe2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 2478/2478 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: opening_prices_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/opening_prices_2_offline_fg_materialization/executions\n",
      "2025-12-29 11:35:22,042 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-12-29 11:35:34,842 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-12-29 11:35:38,031 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-12-29 11:37:39,618 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-12-29 11:37:39,795 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-29 11:37:55,140 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('opening_prices_2_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data_clean = stock_data_clean.reset_index() # get index as date column\n",
    "\n",
    "stock_data_clean.columns = stock_data_clean.columns.str.lower()\n",
    "\n",
    "# Create the feature group for stock opening prices\n",
    "fg = fs.get_or_create_feature_group(\n",
    "    name=\"opening_prices\", \n",
    "    description=\"AAPL opening prices with next-day target\",\n",
    "    version = 2,\n",
    "    primary_key = ['date'],\n",
    "    event_time = 'date'\n",
    "    )\n",
    "fg.insert(stock_data_clean, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d570b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'sentiment_polarity', 'sentiment_neg', 'sentiment_neu',\n",
      "       'sentiment_pos'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1574/1574 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sentiments_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/sentiments_2_offline_fg_materialization/executions\n",
      "2025-12-29 11:38:21,342 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-12-29 11:38:30,911 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-12-29 11:40:38,372 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-12-29 11:40:38,532 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-29 11:40:47,124 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('sentiments_2_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_daily = sentiment_daily.reset_index() # get index as date column\n",
    "\n",
    "sentiment_daily.columns = sentiment_daily.columns.str.lower()\n",
    "\n",
    "print(sentiment_daily.columns)\n",
    "\n",
    "# Create the feature group for stock opening prices\n",
    "fg = fs.get_or_create_feature_group(\n",
    "    name=\"sentiments\", \n",
    "    description=\"AAPL stock sentiments\",\n",
    "    version = 2,\n",
    "    primary_key = ['date'],\n",
    "    event_time = 'date'\n",
    "    )\n",
    "fg.insert(sentiment_daily, wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
