{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e319d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cded6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-29 12:10:56,655 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-12-29 12:10:56,658 INFO: Initializing external client\n",
      "2025-12-29 12:10:56,658 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-12-29 12:10:58,468 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267871\n",
      "Successfully connected to Feature Store: a1id2223_featurestore\n",
      "HSFS Version: 4.2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1767006663.613|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.188:9093/1]: ssl://51.161.81.188:9093/1: Disconnected: SSL connection closed by peer (after 50118ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "# 1. Login\n",
    "project = hopsworks.login()\n",
    "\n",
    "# 2. Get the Feature Store (This triggers the metadata check)\n",
    "try:\n",
    "    fs = project.get_feature_store(\"A1ID2223\")\n",
    "    print(f\"Successfully connected to Feature Store: {fs.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature Store Connection Error: {e}\")\n",
    "\n",
    "# 3. Check versions\n",
    "print(f\"HSFS Version: {hsfs.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ad73b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature groups\n",
    "sentiment_fg = fs.get_feature_group(\"sentiments\", version=2)\n",
    "opening_price_fg = fs.get_feature_group(\"opening_prices\", version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62f59b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get yahoo ticker for news and stock price\n",
    "ticker = yf.Ticker(\"AAPL\")\n",
    "sentiments = ticker.news\n",
    "price = ticker.history(period=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60d393fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentiments = []\n",
    "# Process sentiment -> [(title, summary)]\n",
    "for sentiment in sentiments:\n",
    "    content = sentiment[\"content\"]\n",
    "    title = content[\"title\"]\n",
    "    summary = content[\"summary\"]\n",
    "    cleaned_sentiments.append((title, summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d8a78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Quick check for device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Simple FinBERT sentiment pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Optional: alias for compatibility with other cells\n",
    "sentiment_nlp = classifier\n",
    "\n",
    "# Initialise the sentiment scores (if needed later)\n",
    "sentiment_neg, sentiment_pos, sentiment_neu = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5afd0c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-29 12:11:24,668 WARNING: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "\n",
      "FinBERT model moved to MPS device\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT sentiment pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import pipeline as hf_pipeline\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_nlp = hf_pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Try to move model to Apple Silicon MPS if available\n",
    "if torch.backends.mps.is_available():\n",
    "    try:\n",
    "        model.to(\"mps\")\n",
    "        print(\"FinBERT model moved to MPS device\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not move model to mps: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c45e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investors know about the AI bubble. They're buying AI stock anyway.\n",
      "Apple CEO Tim Cook Just Gave Nike Investors 3 Million Reasons to Cheer\n",
      "Major shop closures across the UK, mapped\n",
      "Financial resolutions for the New Year to help you make the most of your money\n",
      "Should You Buy the Best-Performing \"Magnificent Seven\" Stock of 2025?\n",
      "Dow Jones Futures Waver With Market At Highs; Tesla, Nvidia In Buy Areas\n",
      "A guide to choosing the right Apple Watch\n",
      "The Next Stock-Split Stock That Could Make You Rich\n",
      "Globalstar (GSAT) Gains Strategic Value From Apple Direct-to-Device Partnership\n",
      "Jim Cramer Repeats His “Own It, Don’t Trade It” Mantra on Apple\n",
      "Scored 10 articles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timezone\n",
    "\n",
    "rows = []\n",
    "# Score each article with FinBERT and collect per-article probabilities\n",
    "for item in sentiments or []:\n",
    "    content = item.get(\"content\", {})\n",
    "    title = content.get(\"title\") or \"\"\n",
    "    summary = content.get(\"summary\") or \"\"\n",
    "    text = f\"{title}. {summary}\".strip()\n",
    "    print(title)\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    # Derive publish date from providerPublishTime (unix seconds)\n",
    "    ts = item.get(\"providerPublishTime\")\n",
    "    if ts is None:\n",
    "        dt = pd.Timestamp.utcnow().normalize()\n",
    "    else:\n",
    "        # Convert to UTC, drop timezone, normalize to date\n",
    "        dt = pd.to_datetime(ts, unit=\"s\", utc=True).tz_convert(None).normalize()\n",
    "\n",
    "    # Run FinBERT and get probabilities for all classes\n",
    "    all_scores = sentiment_nlp(text)[0]  # [{label: 'positive'|'negative'|'neutral', score: float}, ...]\n",
    "    score_map = {s[\"label\"].lower(): s[\"score\"] for s in all_scores}\n",
    "\n",
    "    pos = score_map.get(\"positive\", 0.0)\n",
    "    neg = score_map.get(\"negative\", 0.0)\n",
    "    neu = score_map.get(\"neutral\", 0.0)\n",
    "    polarity = pos - neg\n",
    "\n",
    "    rows.append({\n",
    "        \"date\": dt,\n",
    "        \"sentiment_pos\": pos,\n",
    "        \"sentiment_neg\": neg,\n",
    "        \"sentiment_neu\": neu,\n",
    "        \"sentiment_polarity\": polarity,\n",
    "    })\n",
    "\n",
    "article_df = pd.DataFrame(rows)\n",
    "print(f\"Scored {len(article_df)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "969e5ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sentiment_polarity  sentiment_neg  sentiment_neu  sentiment_pos\n",
      "date                                                                       \n",
      "2025-12-29            0.069065       0.125002       0.680932       0.194067\n"
     ]
    }
   ],
   "source": [
    "# Aggregate to daily means to match backfill features\n",
    "if not article_df.empty:\n",
    "    article_df[\"date\"] = pd.to_datetime(article_df[\"date\"]).dt.normalize()\n",
    "    sentiment_daily = (\n",
    "        article_df.groupby(\"date\").agg({\n",
    "            \"sentiment_polarity\": \"mean\",\n",
    "            \"sentiment_neg\": \"mean\",\n",
    "            \"sentiment_neu\": \"mean\",\n",
    "            \"sentiment_pos\": \"mean\",\n",
    "        })\n",
    "    )\n",
    "    # Ensure timezone-naive index named 'date'\n",
    "    sentiment_daily.index = sentiment_daily.index.tz_localize(None)\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(sentiment_daily.head())\n",
    "else:\n",
    "    sentiment_daily = pd.DataFrame(\n",
    "        columns=[\"sentiment_polarity\", \"sentiment_neg\", \"sentiment_neu\", \"sentiment_pos\"]\n",
    "    )\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(\"No articles found for daily aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4673db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sentiments_2_offline_fg_materialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1767006714.831|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.208:9093/2]: ssl://51.161.81.208:9093/2: Disconnected: SSL connection closed by peer (after 50122ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Ensure feature group alignment with backfill\u001b[39;00m\n\u001b[32m      7\u001b[39m     fg = fs.get_or_create_feature_group(\n\u001b[32m      8\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33msentiments\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m         description=\u001b[33m\"\u001b[39m\u001b[33mAAPL stock sentiments\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m         event_time=\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_to_insert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInserted daily sentiments into feature store\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hsfs/feature_group.py:3053\u001b[39m, in \u001b[36mFeatureGroup.insert\u001b[39m\u001b[34m(self, features, overwrite, operation, storage, write_options, validation_options, wait, transformation_context, transform)\u001b[39m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._offline_backfill_every_hr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3051\u001b[39m     write_options[\u001b[33m\"\u001b[39m\u001b[33moffline_backfill_every_hr\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._offline_backfill_every_hr\n\u001b[32m-> \u001b[39m\u001b[32m3053\u001b[39m job, ge_report = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3054\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msave_report\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformation_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3065\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine.get_type().startswith(\u001b[33m\"\u001b[39m\u001b[33mspark\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m   3066\u001b[39m     \u001b[38;5;66;03m# Also, only compute statistics if stream is False.\u001b[39;00m\n\u001b[32m   3067\u001b[39m     \u001b[38;5;66;03m# if True, the backfill job has not been triggered and the data has not been inserted (it's in Kafka)\u001b[39;00m\n\u001b[32m   3068\u001b[39m     \u001b[38;5;28mself\u001b[39m.compute_statistics()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hsfs/core/feature_group_engine.py:224\u001b[39m, in \u001b[36mFeatureGroupEngine.insert\u001b[39m\u001b[34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options, transformation_context, transform)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overwrite:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mself\u001b[39m._feature_group_api.delete_content(feature_group)\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbulk_insert\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43monline_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43monline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    233\u001b[39m     ge_report,\n\u001b[32m    234\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hsfs/engine/python.py:815\u001b[39m, in \u001b[36mEngine.save_dataframe\u001b[39m\u001b[34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[39m\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_dataframe\u001b[39m(\n\u001b[32m    801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    802\u001b[39m     feature_group: FeatureGroup,\n\u001b[32m   (...)\u001b[39m\u001b[32m    809\u001b[39m     validation_id: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    810\u001b[39m ) -> Optional[job.Job]:\n\u001b[32m    811\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    812\u001b[39m         \u001b[38;5;28mhasattr\u001b[39m(feature_group, \u001b[33m\"\u001b[39m\u001b[33mEXTERNAL_FEATURE_GROUP\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    813\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m feature_group.online_enabled\n\u001b[32m    814\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m feature_group.stream:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_dataframe_kafka\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffline_write_options\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    819\u001b[39m         \u001b[38;5;66;03m# for backwards compatibility\u001b[39;00m\n\u001b[32m    820\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.legacy_save_dataframe(\n\u001b[32m    821\u001b[39m             feature_group,\n\u001b[32m    822\u001b[39m             dataframe,\n\u001b[32m   (...)\u001b[39m\u001b[32m    828\u001b[39m             validation_id,\n\u001b[32m    829\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hsfs/engine/python.py:1601\u001b[39m, in \u001b[36mEngine._write_dataframe_kafka\u001b[39m\u001b[34m(self, feature_group, dataframe, offline_write_options)\u001b[39m\n\u001b[32m   1599\u001b[39m         initial_check_point = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1600\u001b[39m     \u001b[38;5;66;03m# provide the initial_check_point as it will reduce the read amplification of materialization job\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1601\u001b[39m     \u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaterialization_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1602\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaterialization_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdefaultArgs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1603\u001b[39m \u001b[43m        \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m -initialCheckPointString \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minitial_check_point\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1605\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minitial_check_point\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1607\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_termination\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffline_write_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwait_for_job\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1609\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1611\u001b[39m \u001b[38;5;66;03m# wait for online ingestion\u001b[39;00m\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_group.online_enabled \u001b[38;5;129;01mand\u001b[39;00m offline_write_options.get(\n\u001b[32m   1613\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwait_for_online_ingestion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1614\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hopsworks_common/usage.py:242\u001b[39m, in \u001b[36mmethod_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# Call the original method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hopsworks_common/job.py:180\u001b[39m, in \u001b[36mJob.run\u001b[39m\u001b[34m(self, args, await_termination)\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLaunching job: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m execution = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execution_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob started successfully, you can follow the progress at \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexecution.get_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    183\u001b[39m )\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m await_termination:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hopsworks_common/core/execution_api.py:26\u001b[39m, in \u001b[36mExecutionApi._start\u001b[39m\u001b[34m(self, job, args)\u001b[39m\n\u001b[32m     22\u001b[39m _client = client.get_instance()\n\u001b[32m     23\u001b[39m path_params = [\u001b[33m\"\u001b[39m\u001b[33mproject\u001b[39m\u001b[33m\"\u001b[39m, _client._project_id, \u001b[33m\"\u001b[39m\u001b[33mjobs\u001b[39m\u001b[33m\"\u001b[39m, job.name, \u001b[33m\"\u001b[39m\u001b[33mexecutions\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m execution.Execution.from_response_json(\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, job\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hopsworks_common/decorators.py:48\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst._connected:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/hopsworks_common/client/base.py:177\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    174\u001b[39m _logger.debug(\u001b[33m\"\u001b[39m\u001b[33murl:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m hostname_verification:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(url, \u001b[38;5;28mself\u001b[39m._verify))\n\u001b[32m    176\u001b[39m prepped = \u001b[38;5;28mself\u001b[39m._session.prepare_request(request)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m401\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.REST_ENDPOINT \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    180\u001b[39m     \u001b[38;5;66;03m# refresh token and retry request - only on hopsworks\u001b[39;00m\n\u001b[32m    181\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._retry_token_expired(\n\u001b[32m    182\u001b[39m         request, stream, \u001b[38;5;28mself\u001b[39m.TOKEN_EXPIRED_RETRY_INTERVAL, \u001b[32m1\u001b[39m\n\u001b[32m    183\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1733\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, on_post_connection, on_upload_body, on_early_response, extension, multiplexed, **response_kw)\u001b[39m\n\u001b[32m   1730\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1732\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1733\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload,misc]\u001b[39;49;00m\n\u001b[32m   1734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m    \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_post_connection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_post_connection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_upload_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_upload_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_early_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_early_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiplexed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiplexed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextension\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1751\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1753\u001b[39m \u001b[38;5;66;03m# it was established a non-multiplexed connection. fallback to original behavior.\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ResponsePromise):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1375\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length, on_post_connection, on_upload_body, on_early_response, extension, multiplexed)\u001b[39m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pool.borrow(rp) \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1375\u001b[39m         response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpolice_officer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mearly_response_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_early_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1380\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/urllib3/connection.py:634\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self, promise, police_officer, early_response_callback)\u001b[39m\n\u001b[32m    631\u001b[39m     early_response_callback(early_response)\n\u001b[32m    633\u001b[39m \u001b[38;5;66;03m# Get the response from backend._base.BaseBackend\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m low_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpromise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpromise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_response_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_response_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m promise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    640\u001b[39m     promise = low_response.from_promise\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/urllib3/backend/hface.py:1532\u001b[39m, in \u001b[36mHfaceBackend.getresponse\u001b[39m\u001b[34m(self, promise, early_response_callback)\u001b[39m\n\u001b[32m   1529\u001b[39m     stream_id = promise.stream_id \u001b[38;5;28;01mif\u001b[39;00m promise \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;66;03m# Usually, will be a single event in array. We should be able to handle the case >1 too, but we actually don't.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m head_event: HeadersReceived | EarlyHeadersReceived = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__exchange_until\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m   1533\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mHeadersReceived\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEarlyHeadersReceived\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreceive_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent_type_collectable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m        \u001b[49m\u001b[43mHeadersReceived\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEarlyHeadersReceived\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrespect_end_stream_signal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stop as soon as we get either (collectable) event.\u001b[39;49;00m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.pop()\n\u001b[32m   1546\u001b[39m \u001b[38;5;66;03m# we want to have a view on last conn was used\u001b[39;00m\n\u001b[32m   1547\u001b[39m \u001b[38;5;66;03m# ...in the sense that we spoke with the remote peer.\u001b[39;00m\n\u001b[32m   1548\u001b[39m \u001b[38;5;28mself\u001b[39m._last_used_at = time.monotonic()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/nlp-stock-prediction/.venv/lib/python3.12/site-packages/urllib3/backend/hface.py:908\u001b[39m, in \u001b[36mHfaceBackend.__exchange_until\u001b[39m\u001b[34m(self, event_type, receive_first, event_type_collectable, respect_end_stream_signal, maximal_data_in_read, data_in_len_from, stream_id)\u001b[39m\n\u001b[32m    905\u001b[39m         \u001b[38;5;28mself\u001b[39m.sock.sendall(data_out)\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m     data_in = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mConnectionAbortedError\u001b[39;00m, \u001b[38;5;167;01mConnectionResetError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, \u001b[38;5;167;01mConnectionResetError\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    911\u001b[39m         event_type \u001b[38;5;129;01mis\u001b[39;00m HandshakeCompleted\n\u001b[32m    912\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m    915\u001b[39m         )\n\u001b[32m    916\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Insert aggregated sentiments into Hopsworks Feature Store\n",
    "if sentiment_daily is not None and not sentiment_daily.empty:\n",
    "    df_to_insert = sentiment_daily.reset_index()\n",
    "    df_to_insert.columns = df_to_insert.columns.str.lower()\n",
    "\n",
    "    # Ensure feature group alignment with backfill\n",
    "    fg = fs.get_or_create_feature_group(\n",
    "        name=\"sentiments\",\n",
    "        description=\"AAPL stock sentiments\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    fg.insert(df_to_insert, wait=True)\n",
    "    print(\"Inserted daily sentiments into feature store\")\n",
    "else:\n",
    "    print(\"No sentiment data to insert today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2beb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.29s) \n",
      "Latest sentiment entries:\n",
      "                          date  sentiment_polarity  sentiment_neg  \\\n",
      "1    2025-12-29 00:00:00+00:00            0.069065       0.125002   \n",
      "0    2025-12-23 00:00:00+00:00            0.298535       0.131626   \n",
      "1513 2024-11-27 00:00:00+00:00            0.000000       0.000000   \n",
      "574  2024-11-26 00:00:00+00:00            0.000000       0.000000   \n",
      "1555 2024-11-25 00:00:00+00:00            0.000000       0.000000   \n",
      "\n",
      "      sentiment_neu  sentiment_pos  \n",
      "1          0.680932       0.194067  \n",
      "0          0.438214       0.430160  \n",
      "1513       1.000000       0.000000  \n",
      "574        1.000000       0.000000  \n",
      "1555       1.000000       0.000000  \n",
      "\n",
      "Today's sentiment (2025-12-29):\n",
      "                       date  sentiment_polarity  sentiment_neg  sentiment_neu  \\\n",
      "1 2025-12-29 00:00:00+00:00            0.069065       0.125002       0.680932   \n",
      "\n",
      "   sentiment_pos  \n",
      "1       0.194067  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1767005165.591|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 50119ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    }
   ],
   "source": [
    "# Read all data from sentiments feature group\n",
    "sentiments_fg = fs.get_feature_group(\"sentiments\", version=2)\n",
    "sentiments_df = sentiments_fg.read()\n",
    "\n",
    "# Sort by date and show the most recent entries\n",
    "latest = sentiments_df.sort_values('date', ascending=False).head(5)\n",
    "print(\"Latest sentiment entries:\")\n",
    "print(latest)\n",
    "\n",
    "# Verify today's date is present\n",
    "today = pd.Timestamp.utcnow().normalize()\n",
    "today_data = sentiments_df[sentiments_df['date'] == today]\n",
    "print(f\"\\nToday's sentiment ({today.date()}):\")\n",
    "print(today_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert today's stock price into Hopsworks Feature Store\n",
    "# if not price.empty:\n",
    "#     # Prepare stock data to match backfill format\n",
    "#     stock_today = price[['Open']].copy()\n",
    "    \n",
    "#     # Remove timezone and normalize to date only\n",
    "#     stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "#     stock_today.index.name = 'date'\n",
    "    \n",
    "#     # Reset index to get date as column and lowercase column names\n",
    "#     stock_insert = stock_today.reset_index()\n",
    "#     stock_insert.columns = stock_insert.columns.str.lower()\n",
    "    \n",
    "#     print(\"Stock data to insert:\")\n",
    "#     print(stock_insert)\n",
    "    \n",
    "#     # Get or create the feature group (should already exist from backfill)\n",
    "#     opening_fg = fs.get_or_create_feature_group(\n",
    "#         name=\"opening_prices\",\n",
    "#         description=\"AAPL opening prices\",\n",
    "#         version=1,\n",
    "#         primary_key=[\"date\"],\n",
    "#         event_time=\"date\",\n",
    "#     )\n",
    "#     opening_fg.insert(stock_insert, wait=True)\n",
    "#     print(\"Inserted today's opening price into feature store\")\n",
    "# else:\n",
    "#     print(\"No stock price data available for today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08f92a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: opening_prices_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/opening_prices_2_offline_fg_materialization/executions\n",
      "2025-12-29 11:46:32,623 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-12-29 11:46:48,697 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1767005216.807|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.188:9093/1]: ssl://51.161.81.188:9093/1: Disconnected: SSL connection closed by peer (after 50159ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005310.659|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.188:9093/1]: ssl://51.161.81.188:9093/1: Disconnected: SSL connection closed by peer (after 92794ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-29 11:48:38,232 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-12-29 11:48:38,404 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-29 11:48:50,491 INFO: Execution finished successfully.\n",
      "Inserted today's opening price (with target_open NA) into feature store\n"
     ]
    }
   ],
   "source": [
    "# Insert today's stock price into opening_prices v2 (with placeholder target)\n",
    "if not price.empty:\n",
    "    stock_today = price[[\"Open\"]].copy()\n",
    "    stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "    stock_today.index.name = 'date'\n",
    "\n",
    "    stock_insert = stock_today.reset_index()\n",
    "    stock_insert.columns = stock_insert.columns.str.lower()  # ['date','open']\n",
    "\n",
    "    # Match FG schema: include target_open as unknown for today\n",
    "    stock_insert['target_open'] = pd.NA\n",
    "\n",
    "    opening_fg = fs.get_or_create_feature_group(\n",
    "        name=\"opening_prices\",\n",
    "        description=\"AAPL opening prices with next-day target\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    opening_fg.insert(stock_insert, wait=True)\n",
    "    print(\"Inserted today's opening price (with target_open NA) into feature store\")\n",
    "else:\n",
    "    print(\"No stock price data available for today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21cab0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open\n",
      "Date                                 \n",
      "2025-12-26 00:00:00-05:00  274.160004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1767005361.334|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 50121ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005412.525|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 50115ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005463.795|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.188:9093/1]: ssl://51.161.81.188:9093/1: Disconnected: SSL connection closed by peer (after 50173ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005514.994|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 50165ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005610.663|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 94602ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005661.630|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.208:9093/2]: ssl://51.161.81.208:9093/2: Disconnected: SSL connection closed by peer (after 50167ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005712.847|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 50185ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005764.030|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.188:9093/1]: ssl://51.161.81.188:9093/1: Disconnected: SSL connection closed by peer (after 50152ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767005815.230|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 50155ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    }
   ],
   "source": [
    "stock_today = price[[\"Open\"]].copy()\n",
    "print(stock_today.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a31acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c763da426964db586a2df4d926b652a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/441617 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's Open: 274.1600036621094irs, 1 files)... DONE\n",
      "Today's Sentiment: \n",
      "sentiment_polarity    0.069065\n",
      "sentiment_neg         0.125002\n",
      "sentiment_neu         0.680932\n",
      "sentiment_pos         0.194067\n",
      "Name: 2025-12-29 00:00:00, dtype: float64\n",
      "\n",
      "Prediction for next trading day (30th): 191.22506713867188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1767006064.208|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.81.208:9093/2]: ssl://51.161.81.208:9093/2: Disconnected: SSL connection closed by peer (after 50124ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1767006115.401|FAIL|rdkafka#producer-5| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected: SSL connection closed by peer (after 50117ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    }
   ],
   "source": [
    "# Manual prediction since FS insert failed\n",
    "import xgboost\n",
    "import os\n",
    "\n",
    "# Get model\n",
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"sentiment_stock_price_model_AAPL\", version=1)\n",
    "model_dir = model.download()\n",
    "model_path = os.path.join(model_dir, \"model.json\")\n",
    "\n",
    "xgb_model = xgboost.XGBRegressor()\n",
    "xgb_model.load_model(model_path)\n",
    "\n",
    "# Prepare input\n",
    "# We need: sentiment_polarity, sentiment_neg, sentiment_neu, sentiment_pos, opening_prices_open\n",
    "# sentiment_daily has the sentiment columns.\n",
    "# price has the open price.\n",
    "\n",
    "# Get today's open price\n",
    "today_open = price['Open'].iloc[-1]\n",
    "print(f\"Today's Open: {today_open}\")\n",
    "\n",
    "# Get today's sentiment\n",
    "today_sent = sentiment_daily.iloc[-1]\n",
    "print(f\"Today's Sentiment: \\n{today_sent}\")\n",
    "\n",
    "# Create feature vector\n",
    "import pandas as pd\n",
    "X_new = pd.DataFrame({\n",
    "    'sentiment_polarity': [today_sent['sentiment_polarity']],\n",
    "    'sentiment_neg': [today_sent['sentiment_neg']],\n",
    "    'sentiment_neu': [today_sent['sentiment_neu']],\n",
    "    'sentiment_pos': [today_sent['sentiment_pos']],\n",
    "    'opening_prices_open': [today_open]\n",
    "})\n",
    "\n",
    "# Predict\n",
    "pred = xgb_model.predict(X_new)\n",
    "print(f\"\\nPrediction for next trading day (30th): {pred[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
