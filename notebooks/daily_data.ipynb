{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e319d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cded6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-30 16:41:29,698 INFO: Initializing external client\n",
      "2025-12-30 16:41:29,699 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-12-30 16:41:32,431 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267871\n",
      "Successfully connected to Feature Store: a1id2223_featurestore\n",
      "HSFS Version: 4.2.10\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "# 1. Login\n",
    "project = hopsworks.login()\n",
    "\n",
    "# 2. Get the Feature Store (This triggers the metadata check)\n",
    "try:\n",
    "    fs = project.get_feature_store(\"A1ID2223\")\n",
    "    print(f\"Successfully connected to Feature Store: {fs.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature Store Connection Error: {e}\")\n",
    "\n",
    "# 3. Check versions\n",
    "print(f\"HSFS Version: {hsfs.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad73b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature groups\n",
    "sentiment_fg = fs.get_feature_group(\"sentiments\", version=2)\n",
    "opening_price_fg = fs.get_feature_group(\"opening_prices\", version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f59b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get yahoo ticker for news and stock price\n",
    "ticker = yf.Ticker(\"AAPL\")\n",
    "sentiments = ticker.news\n",
    "price = ticker.history(period=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d393fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentiments = []\n",
    "# Process sentiment -> [(title, summary)]\n",
    "for sentiment in sentiments:\n",
    "    content = sentiment[\"content\"]\n",
    "    title = content[\"title\"]\n",
    "    summary = content[\"summary\"]\n",
    "    cleaned_sentiments.append((title, summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8a78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Quick check for device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Simple FinBERT sentiment pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Optional: alias for compatibility with other cells\n",
    "sentiment_nlp = classifier\n",
    "\n",
    "# Initialise the sentiment scores (if needed later)\n",
    "sentiment_neg, sentiment_pos, sentiment_neu = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afd0c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-30 16:41:44,959 WARNING: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "\n",
      "FinBERT model moved to MPS device\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT sentiment pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import pipeline as hf_pipeline\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_nlp = hf_pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Try to move model to Apple Silicon MPS if available\n",
    "if torch.backends.mps.is_available():\n",
    "    try:\n",
    "        model.to(\"mps\")\n",
    "        print(\"FinBERT model moved to MPS device\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not move model to mps: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c45e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warren Buffett is retiring — here's what his favorite indicator reveals about the stock market\n",
      "Intel stock soared in 2025. But the chipmaker still has a long road ahead.\n",
      "With the legendary Warren Buffett stepping back, Berkshire Hathaway enters a new era\n",
      "BNY Mellon’s Large Cap ETF Popped 40% on a Nonstop Run\n",
      "Microsoft and Palantir Lead Wedbush's Top AI Picks for 2026\n",
      "The Zacks Analyst Blog Highlights Apple, Cisco Systems and IBM\n",
      "Tech giants accused of snooping on radio listeners\n",
      "US Equities Fall in Muted Trading as Nvidia, Tesla Decline\n",
      "Tim Cook's Nike Buy, AI Smart Glasses, Court Victory And More: This Week In Appleverse\n",
      "Warren Buffett gifts us 5 secrets for investing success, as he hands off Berkshire’s reins this week\n",
      "Scored 10 articles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timezone\n",
    "\n",
    "rows = []\n",
    "# Score each article with FinBERT and collect per-article probabilities\n",
    "for item in sentiments or []:\n",
    "    content = item.get(\"content\", {})\n",
    "    title = content.get(\"title\") or \"\"\n",
    "    summary = content.get(\"summary\") or \"\"\n",
    "    text = f\"{title}. {summary}\".strip()\n",
    "    print(title)\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    # Derive publish date from providerPublishTime (unix seconds)\n",
    "    ts = item.get(\"providerPublishTime\")\n",
    "    if ts is None:\n",
    "        dt = pd.Timestamp.utcnow().normalize()\n",
    "    else:\n",
    "        # Convert to UTC, drop timezone, normalize to date\n",
    "        dt = pd.to_datetime(ts, unit=\"s\", utc=True).tz_convert(None).normalize()\n",
    "\n",
    "    # Run FinBERT and get probabilities for all classes\n",
    "    all_scores = sentiment_nlp(text)[0]  # [{label: 'positive'|'negative'|'neutral', score: float}, ...]\n",
    "    score_map = {s[\"label\"].lower(): s[\"score\"] for s in all_scores}\n",
    "\n",
    "    pos = score_map.get(\"positive\", 0.0)\n",
    "    neg = score_map.get(\"negative\", 0.0)\n",
    "    neu = score_map.get(\"neutral\", 0.0)\n",
    "    polarity = pos - neg\n",
    "\n",
    "    rows.append({\n",
    "        \"date\": dt,\n",
    "        \"sentiment_pos\": pos,\n",
    "        \"sentiment_neg\": neg,\n",
    "        \"sentiment_neu\": neu,\n",
    "        \"sentiment_polarity\": polarity,\n",
    "    })\n",
    "\n",
    "article_df = pd.DataFrame(rows)\n",
    "print(f\"Scored {len(article_df)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969e5ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sentiment_polarity  sentiment_neg  sentiment_neu  sentiment_pos\n",
      "date                                                                       \n",
      "2025-12-30            0.118052       0.183541       0.514867       0.301592\n"
     ]
    }
   ],
   "source": [
    "# Aggregate to daily means to match backfill features\n",
    "if not article_df.empty:\n",
    "    article_df[\"date\"] = pd.to_datetime(article_df[\"date\"]).dt.normalize()\n",
    "    sentiment_daily = (\n",
    "        article_df.groupby(\"date\").agg({\n",
    "            \"sentiment_polarity\": \"mean\",\n",
    "            \"sentiment_neg\": \"mean\",\n",
    "            \"sentiment_neu\": \"mean\",\n",
    "            \"sentiment_pos\": \"mean\",\n",
    "        })\n",
    "    )\n",
    "    # Ensure timezone-naive index named 'date'\n",
    "    sentiment_daily.index = sentiment_daily.index.tz_localize(None)\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(sentiment_daily.head())\n",
    "else:\n",
    "    sentiment_daily = pd.DataFrame(\n",
    "        columns=[\"sentiment_polarity\", \"sentiment_neg\", \"sentiment_neu\", \"sentiment_pos\"]\n",
    "    )\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(\"No articles found for daily aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4673db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sentiments_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/sentiments_2_offline_fg_materialization/executions\n",
      "2025-12-30 16:42:16,618 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-12-30 16:42:19,907 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-12-30 16:44:13,307 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-12-30 16:44:13,562 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-30 16:44:26,065 INFO: Execution finished successfully.\n",
      "Inserted daily sentiments into feature store\n"
     ]
    }
   ],
   "source": [
    "# Insert aggregated sentiments into Hopsworks Feature Store\n",
    "if sentiment_daily is not None and not sentiment_daily.empty:\n",
    "    df_to_insert = sentiment_daily.reset_index()\n",
    "    df_to_insert.columns = df_to_insert.columns.str.lower()\n",
    "\n",
    "    # Ensure feature group alignment with backfill\n",
    "    fg = fs.get_or_create_feature_group(\n",
    "        name=\"sentiments\",\n",
    "        description=\"AAPL stock sentiments\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    fg.insert(df_to_insert, wait=True)\n",
    "    print(\"Inserted daily sentiments into feature store\")\n",
    "else:\n",
    "    print(\"No sentiment data to insert today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2beb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.84s) \n",
      "Latest sentiment entries:\n",
      "                          date  sentiment_polarity  sentiment_neg  \\\n",
      "1576 2025-12-30 00:00:00+00:00            0.118052       0.183541   \n",
      "1    2025-12-29 00:00:00+00:00           -0.028438       0.218143   \n",
      "0    2025-12-23 00:00:00+00:00            0.298535       0.131626   \n",
      "1513 2024-11-27 00:00:00+00:00            0.000000       0.000000   \n",
      "574  2024-11-26 00:00:00+00:00            0.000000       0.000000   \n",
      "\n",
      "      sentiment_neu  sentiment_pos  \n",
      "1576       0.514867       0.301592  \n",
      "1          0.592153       0.189705  \n",
      "0          0.438214       0.430160  \n",
      "1513       1.000000       0.000000  \n",
      "574        1.000000       0.000000  \n",
      "\n",
      "Today's sentiment (2025-12-30):\n",
      "                          date  sentiment_polarity  sentiment_neg  \\\n",
      "1576 2025-12-30 00:00:00+00:00            0.118052       0.183541   \n",
      "\n",
      "      sentiment_neu  sentiment_pos  \n",
      "1576       0.514867       0.301592  \n"
     ]
    }
   ],
   "source": [
    "# Read all data from sentiments feature group\n",
    "sentiments_fg = fs.get_feature_group(\"sentiments\", version=2)\n",
    "sentiments_df = sentiments_fg.read()\n",
    "\n",
    "# Sort by date and show the most recent entries\n",
    "latest = sentiments_df.sort_values('date', ascending=False).head(5)\n",
    "print(\"Latest sentiment entries:\")\n",
    "print(latest)\n",
    "\n",
    "# Verify today's date is present\n",
    "today = pd.Timestamp.utcnow().normalize()\n",
    "today_data = sentiments_df[sentiments_df['date'] == today]\n",
    "print(f\"\\nToday's sentiment ({today.date()}):\")\n",
    "print(today_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a7e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert today's stock price into Hopsworks Feature Store\n",
    "# if not price.empty:\n",
    "#     # Prepare stock data to match backfill format\n",
    "#     stock_today = price[['Open']].copy()\n",
    "    \n",
    "#     # Remove timezone and normalize to date only\n",
    "#     stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "#     stock_today.index.name = 'date'\n",
    "    \n",
    "#     # Reset index to get date as column and lowercase column names\n",
    "#     stock_insert = stock_today.reset_index()\n",
    "#     stock_insert.columns = stock_insert.columns.str.lower()\n",
    "    \n",
    "#     print(\"Stock data to insert:\")\n",
    "#     print(stock_insert)\n",
    "    \n",
    "#     # Get or create the feature group (should already exist from backfill)\n",
    "#     opening_fg = fs.get_or_create_feature_group(\n",
    "#         name=\"opening_prices\",\n",
    "#         description=\"AAPL opening prices\",\n",
    "#         version=1,\n",
    "#         primary_key=[\"date\"],\n",
    "#         event_time=\"date\",\n",
    "#     )\n",
    "#     opening_fg.insert(stock_insert, wait=True)\n",
    "#     print(\"Inserted today's opening price into feature store\")\n",
    "# else:\n",
    "#     print(\"No stock price data available for today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f92a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2025-12-30 00:00:00-05:00  272.834991  274.079987  272.394806  272.709991   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits  \n",
      "Date                                                         \n",
      "2025-12-30 00:00:00-05:00  4671811        0.0           0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: opening_prices_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/opening_prices_2_offline_fg_materialization/executions\n",
      "2025-12-30 16:45:16,224 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-12-30 16:45:19,535 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-12-30 16:45:22,853 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-12-30 16:47:17,140 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-12-30 16:47:17,373 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-30 16:47:29,916 INFO: Execution finished successfully.\n",
      "Inserted today's opening price (with target_open NA) into feature store\n",
      "        date        open  target_open\n",
      "0 2025-12-30  272.834991          NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(price)\n",
    "\n",
    "# Insert today's stock price into opening_prices v2 (with placeholder target)\n",
    "if not price.empty:\n",
    "    # Refresh feature store connection to avoid timeouts\n",
    "    fs = project.get_feature_store(\"A1ID2223\")\n",
    "    \n",
    "    stock_today = price[[\"Open\"]].copy()\n",
    "    stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "    stock_today.index.name = 'date'\n",
    "\n",
    "    stock_insert = stock_today.reset_index()\n",
    "    stock_insert.columns = stock_insert.columns.str.lower()  # ['date','open']\n",
    "\n",
    "    # Match FG schema: include target_open as unknown for today\n",
    "    # Use np.nan instead of pd.NA for better compatibility with float columns\n",
    "    stock_insert['target_open'] = np.nan\n",
    "\n",
    "    opening_fg = fs.get_or_create_feature_group(\n",
    "        name=\"opening_prices\",\n",
    "        description=\"AAPL opening prices with next-day target\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    opening_fg.insert(stock_insert, wait=True)\n",
    "    print(\"Inserted today's opening price (with target_open NA) into feature store\")\n",
    "    print(stock_insert)\n",
    "else:\n",
    "    print(\"No stock price data available for today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21cab0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open\n",
      "Date                                 \n",
      "2025-12-30 00:00:00-05:00  272.834991\n"
     ]
    }
   ],
   "source": [
    "stock_today = price[[\"Open\"]].copy()\n",
    "print(stock_today.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a31acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9e85da02af494da411e678942c5ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/441617 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's Open: 272.8349914550781irs, 1 files)... DONE\n",
      "Today's Sentiment: \n",
      "sentiment_polarity    0.118052\n",
      "sentiment_neg         0.183541\n",
      "sentiment_neu         0.514867\n",
      "sentiment_pos         0.301592\n",
      "Name: 2025-12-30 00:00:00, dtype: float64\n",
      "\n",
      "Prediction for next trading day (30th): 190.91873168945312\n"
     ]
    }
   ],
   "source": [
    "# Manual prediction since FS insert failed\n",
    "import xgboost\n",
    "import os\n",
    "\n",
    "# Get model\n",
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"sentiment_stock_price_model_AAPL\", version=1)\n",
    "model_dir = model.download()\n",
    "model_path = os.path.join(model_dir, \"model.json\")\n",
    "\n",
    "xgb_model = xgboost.XGBRegressor()\n",
    "xgb_model.load_model(model_path)\n",
    "\n",
    "# Prepare input\n",
    "# We need: sentiment_polarity, sentiment_neg, sentiment_neu, sentiment_pos, opening_prices_open\n",
    "# sentiment_daily has the sentiment columns.\n",
    "# price has the open price.\n",
    "\n",
    "# Get today's open price\n",
    "today_open = price['Open'].iloc[-1]\n",
    "print(f\"Today's Open: {today_open}\")\n",
    "\n",
    "# Get today's sentiment\n",
    "today_sent = sentiment_daily.iloc[-1]\n",
    "print(f\"Today's Sentiment: \\n{today_sent}\")\n",
    "\n",
    "# Create feature vector\n",
    "import pandas as pd\n",
    "X_new = pd.DataFrame({\n",
    "    'sentiment_polarity': [today_sent['sentiment_polarity']],\n",
    "    'sentiment_neg': [today_sent['sentiment_neg']],\n",
    "    'sentiment_neu': [today_sent['sentiment_neu']],\n",
    "    'sentiment_pos': [today_sent['sentiment_pos']],\n",
    "    'opening_prices_open': [today_open]\n",
    "})\n",
    "\n",
    "# Predict\n",
    "pred = xgb_model.predict(X_new)\n",
    "print(f\"\\nPrediction for next trading day (30th): {pred[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
