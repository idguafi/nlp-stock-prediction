{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e319d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cded6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-28 16:37:16,027 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-12-28 16:37:16,032 INFO: Initializing external client\n",
      "2025-12-28 16:37:16,033 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-12-28 16:37:17,495 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267871\n",
      "Successfully connected to Feature Store: a1id2223_featurestore\n",
      "HSFS Version: 4.2.10\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "# 1. Login\n",
    "project = hopsworks.login()\n",
    "\n",
    "# 2. Get the Feature Store (This triggers the metadata check)\n",
    "try:\n",
    "    fs = project.get_feature_store(\"A1ID2223\")\n",
    "    print(f\"Successfully connected to Feature Store: {fs.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature Store Connection Error: {e}\")\n",
    "\n",
    "# 3. Check versions\n",
    "print(f\"HSFS Version: {hsfs.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ad73b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature groups\n",
    "sentiment_fg = fs.get_feature_group(\"sentiment\", version=1)\n",
    "opening_price_fg = fs.get_feature_group(\"opening_prices\", version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f59b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get yahoo ticker for news and stock price\n",
    "ticker = yf.Ticker(\"AAPL\")\n",
    "sentiments = ticker.news\n",
    "price = ticker.history(period=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60d393fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentiments = []\n",
    "# Process sentiment -> [(title, summary)]\n",
    "for sentiment in sentiments:\n",
    "    content = sentiment[\"content\"]\n",
    "    title = content[\"title\"]\n",
    "    summary = content[\"summary\"]\n",
    "    cleaned_sentiments.append((title, summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d8a78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Quick check for device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Simple FinBERT sentiment pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Optional: alias for compatibility with other cells\n",
    "sentiment_nlp = classifier\n",
    "\n",
    "# Initialise the sentiment scores (if needed later)\n",
    "sentiment_neg, sentiment_pos, sentiment_neu = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5afd0c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-28 16:37:34,127 WARNING: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "\n",
      "FinBERT model moved to MPS device\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT sentiment pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import pipeline as hf_pipeline\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_nlp = hf_pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Try to move model to Apple Silicon MPS if available\n",
    "if torch.backends.mps.is_available():\n",
    "    try:\n",
    "        model.to(\"mps\")\n",
    "        print(\"FinBERT model moved to MPS device\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not move model to mps: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c45e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored 10 articles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timezone\n",
    "\n",
    "rows = []\n",
    "# Score each article with FinBERT and collect per-article probabilities\n",
    "for item in sentiments or []:\n",
    "    content = item.get(\"content\", {})\n",
    "    title = content.get(\"title\") or \"\"\n",
    "    summary = content.get(\"summary\") or \"\"\n",
    "    text = f\"{title}. {summary}\".strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    # Derive publish date from providerPublishTime (unix seconds)\n",
    "    ts = item.get(\"providerPublishTime\")\n",
    "    if ts is None:\n",
    "        dt = pd.Timestamp.utcnow().normalize()\n",
    "    else:\n",
    "        # Convert to UTC, drop timezone, normalize to date\n",
    "        dt = pd.to_datetime(ts, unit=\"s\", utc=True).tz_convert(None).normalize()\n",
    "\n",
    "    # Run FinBERT and get probabilities for all classes\n",
    "    all_scores = sentiment_nlp(text)[0]  # [{label: 'positive'|'negative'|'neutral', score: float}, ...]\n",
    "    score_map = {s[\"label\"].lower(): s[\"score\"] for s in all_scores}\n",
    "\n",
    "    pos = score_map.get(\"positive\", 0.0)\n",
    "    neg = score_map.get(\"negative\", 0.0)\n",
    "    neu = score_map.get(\"neutral\", 0.0)\n",
    "    polarity = pos - neg\n",
    "\n",
    "    rows.append({\n",
    "        \"date\": dt,\n",
    "        \"sentiment_pos\": pos,\n",
    "        \"sentiment_neg\": neg,\n",
    "        \"sentiment_neu\": neu,\n",
    "        \"sentiment_polarity\": polarity,\n",
    "    })\n",
    "\n",
    "article_df = pd.DataFrame(rows)\n",
    "print(f\"Scored {len(article_df)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "969e5ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sentiment_polarity  sentiment_neg  sentiment_neu  sentiment_pos\n",
      "date                                                                       \n",
      "2025-12-28            0.135682       0.161343       0.541632       0.297025\n"
     ]
    }
   ],
   "source": [
    "# Aggregate to daily means to match backfill features\n",
    "if not article_df.empty:\n",
    "    article_df[\"date\"] = pd.to_datetime(article_df[\"date\"]).dt.normalize()\n",
    "    sentiment_daily = (\n",
    "        article_df.groupby(\"date\").agg({\n",
    "            \"sentiment_polarity\": \"mean\",\n",
    "            \"sentiment_neg\": \"mean\",\n",
    "            \"sentiment_neu\": \"mean\",\n",
    "            \"sentiment_pos\": \"mean\",\n",
    "        })\n",
    "    )\n",
    "    # Ensure timezone-naive index named 'date'\n",
    "    sentiment_daily.index = sentiment_daily.index.tz_localize(None)\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(sentiment_daily.head())\n",
    "else:\n",
    "    sentiment_daily = pd.DataFrame(\n",
    "        columns=[\"sentiment_polarity\", \"sentiment_neg\", \"sentiment_neu\", \"sentiment_pos\"]\n",
    "    )\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(\"No articles found for daily aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sentiments_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/sentiments_1_offline_fg_materialization/executions\n",
      "2025-12-28 16:38:18,301 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2025-12-28 16:38:31,050 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: FAILED\n",
      "2025-12-28 16:38:31,265 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-28 16:41:10,601 ERROR: Execution failed with status: FAILED. See the logs for more information.\n",
      "Inserted daily sentiments into feature store\n"
     ]
    }
   ],
   "source": [
    "# Insert aggregated sentiments into Hopsworks Feature Store\n",
    "if sentiment_daily is not None and not sentiment_daily.empty:\n",
    "    df_to_insert = sentiment_daily.reset_index()\n",
    "    df_to_insert.columns = df_to_insert.columns.str.lower()\n",
    "\n",
    "    # Ensure feature group alignment with backfill\n",
    "    fg = fs.get_or_create_feature_group(\n",
    "        name=\"sentiments\",\n",
    "        description=\"AAPL stock sentiments\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    fg.insert(df_to_insert, wait=True)\n",
    "    print(\"Inserted daily sentiments into feature store\")\n",
    "else:\n",
    "    print(\"No sentiment data to insert today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2beb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.37s) \n",
      "Latest sentiment entries:\n",
      "                          date  sentiment_polarity  sentiment_neg  \\\n",
      "1577 2025-12-28 00:00:00+00:00            0.135682       0.161343   \n",
      "1576 2025-12-27 00:00:00+00:00            0.222453       0.160476   \n",
      "1575 2025-12-24 00:00:00+00:00            0.101701       0.123859   \n",
      "1574 2025-12-23 00:00:00+00:00            0.298535       0.131626   \n",
      "1325 2024-11-27 00:00:00+00:00            0.000000       0.000000   \n",
      "\n",
      "      sentiment_neu  sentiment_pos  \n",
      "1577       0.541632       0.297025  \n",
      "1576       0.456595       0.382929  \n",
      "1575       0.650581       0.225560  \n",
      "1574       0.438214       0.430160  \n",
      "1325       1.000000       0.000000  \n",
      "\n",
      "Today's sentiment (2025-12-28):\n",
      "                          date  sentiment_polarity  sentiment_neg  \\\n",
      "1577 2025-12-28 00:00:00+00:00            0.135682       0.161343   \n",
      "\n",
      "      sentiment_neu  sentiment_pos  \n",
      "1577       0.541632       0.297025  \n"
     ]
    }
   ],
   "source": [
    "# Read all data from sentiments feature group\n",
    "sentiments_fg = fs.get_feature_group(\"sentiments\", version=1)\n",
    "sentiments_df = sentiments_fg.read()\n",
    "\n",
    "# Sort by date and show the most recent entries\n",
    "latest = sentiments_df.sort_values('date', ascending=False).head(5)\n",
    "print(\"Latest sentiment entries:\")\n",
    "print(latest)\n",
    "\n",
    "# Verify today's date is present\n",
    "today = pd.Timestamp.utcnow().normalize()\n",
    "today_data = sentiments_df[sentiments_df['date'] == today]\n",
    "print(f\"\\nToday's sentiment ({today.date()}):\")\n",
    "print(today_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a7e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert today's stock price into Hopsworks Feature Store\n",
    "# if not price.empty:\n",
    "#     # Prepare stock data to match backfill format\n",
    "#     stock_today = price[['Open']].copy()\n",
    "    \n",
    "#     # Remove timezone and normalize to date only\n",
    "#     stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "#     stock_today.index.name = 'date'\n",
    "    \n",
    "#     # Reset index to get date as column and lowercase column names\n",
    "#     stock_insert = stock_today.reset_index()\n",
    "#     stock_insert.columns = stock_insert.columns.str.lower()\n",
    "    \n",
    "#     print(\"Stock data to insert:\")\n",
    "#     print(stock_insert)\n",
    "    \n",
    "#     # Get or create the feature group (should already exist from backfill)\n",
    "#     opening_fg = fs.get_or_create_feature_group(\n",
    "#         name=\"opening_prices\",\n",
    "#         description=\"AAPL opening prices\",\n",
    "#         version=1,\n",
    "#         primary_key=[\"date\"],\n",
    "#         event_time=\"date\",\n",
    "#     )\n",
    "#     opening_fg.insert(stock_insert, wait=True)\n",
    "#     print(\"Inserted today's opening price into feature store\")\n",
    "# else:\n",
    "#     print(\"No stock price data available for today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f92a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: opening_prices_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/opening_prices_2_offline_fg_materialization/executions\n",
      "2025-12-28 16:14:08,250 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-12-28 16:14:14,681 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-12-28 16:15:53,698 INFO: Waiting for log aggregation to finish.\n",
      "2025-12-28 16:16:22,328 INFO: Execution finished successfully.\n",
      "Inserted today's opening price (with target_open NA) into feature store\n"
     ]
    }
   ],
   "source": [
    "# Insert today's stock price into opening_prices v2 (with placeholder target)\n",
    "if not price.empty:\n",
    "    stock_today = price[[\"Open\"]].copy()\n",
    "    stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "    stock_today.index.name = 'date'\n",
    "\n",
    "    stock_insert = stock_today.reset_index()\n",
    "    stock_insert.columns = stock_insert.columns.str.lower()  # ['date','open']\n",
    "\n",
    "    # Match FG schema: include target_open as unknown for today\n",
    "    stock_insert['target_open'] = pd.NA\n",
    "\n",
    "    opening_fg = fs.get_or_create_feature_group(\n",
    "        name=\"opening_prices\",\n",
    "        description=\"AAPL opening prices with next-day target\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    opening_fg.insert(stock_insert, wait=True)\n",
    "    print(\"Inserted today's opening price (with target_open NA) into feature store\")\n",
    "else:\n",
    "    print(\"No stock price data available for today\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
