{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e319d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cded6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-02 16:15:18,245 INFO: Initializing external client\n",
      "2026-01-02 16:15:18,246 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-02 16:15:20,003 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1267871\n",
      "Successfully connected to Feature Store: a1id2223_featurestore\n",
      "HSFS Version: 4.2.10\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "\n",
    "# 1. Login\n",
    "project = hopsworks.login()\n",
    "\n",
    "# 2. Get the Feature Store (This triggers the metadata check)\n",
    "try:\n",
    "    fs = project.get_feature_store(\"A1ID2223\")\n",
    "    print(f\"Successfully connected to Feature Store: {fs.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature Store Connection Error: {e}\")\n",
    "\n",
    "# 3. Check versions\n",
    "print(f\"HSFS Version: {hsfs.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad73b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature groups\n",
    "sentiment_fg = fs.get_feature_group(\"sentiments\", version=2)\n",
    "opening_price_fg = fs.get_feature_group(\"opening_prices\", version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f59b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get yahoo ticker for news and stock price\n",
    "ticker = yf.Ticker(\"AAPL\")\n",
    "sentiments = ticker.news\n",
    "price = ticker.history(period=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d393fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentiments = []\n",
    "# Process sentiment -> [(title, summary)]\n",
    "for sentiment in sentiments:\n",
    "    content = sentiment[\"content\"]\n",
    "    title = content[\"title\"]\n",
    "    summary = content[\"summary\"]\n",
    "    cleaned_sentiments.append((title, summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8a78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Quick check for device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Simple FinBERT sentiment pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "# Optional: alias for compatibility with other cells\n",
    "sentiment_nlp = classifier\n",
    "\n",
    "# Initialise the sentiment scores (if needed later)\n",
    "sentiment_neg, sentiment_pos, sentiment_neu = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afd0c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-02 16:15:33,477 WARNING: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "\n",
      "FinBERT model moved to MPS device\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT sentiment pipeline\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import pipeline as hf_pipeline\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "sentiment_nlp = hf_pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Try to move model to Apple Silicon MPS if available\n",
    "if torch.backends.mps.is_available():\n",
    "    try:\n",
    "        model.to(\"mps\")\n",
    "        print(\"FinBERT model moved to MPS device\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not move model to mps: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c45e42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CES 2026: What to expect from the tech industry’s biggest show of the year\n",
      "Apple Cuts Vision Pro Output, Marketing as Demand Weakens\n",
      "Apple Cuts Vision Pro Production and Marketing After Weak Consumer Demand\n",
      "Apple Stock Initiated At Neutral. Here's Why.\n",
      "Equities to Get Boost From Robust Earnings in 2026 But Near-Term Fed Path Uncertain, Analysts Say\n",
      "Apple Stock’s Growth Trajectory Is Challenged in 2026. Why This Analyst Is Staying on the Sidelines.\n",
      "Jim Cramer Shares Very Important Insight About Corning (GLW) & Data Centers\n",
      "Billionaire Peter Thiel Sold Nvidia and Tesla to Buy This Other AI Stock\n",
      "Strong Performance Lifted Apple (APPL) in Q3\n",
      "Stocks Rise Pre-Bell Ahead of First Trading Session of 2026\n",
      "Scored 10 articles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timezone\n",
    "\n",
    "rows = []\n",
    "# Score each article with FinBERT and collect per-article probabilities\n",
    "for item in sentiments or []:\n",
    "    content = item.get(\"content\", {})\n",
    "    title = content.get(\"title\") or \"\"\n",
    "    summary = content.get(\"summary\") or \"\"\n",
    "    text = f\"{title}. {summary}\".strip()\n",
    "    print(title)\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    # Derive publish date from providerPublishTime (unix seconds)\n",
    "    ts = item.get(\"providerPublishTime\")\n",
    "    if ts is None:\n",
    "        dt = pd.Timestamp.utcnow().normalize()\n",
    "    else:\n",
    "        # Convert to UTC, drop timezone, normalize to date\n",
    "        dt = pd.to_datetime(ts, unit=\"s\", utc=True).tz_convert(None).normalize()\n",
    "\n",
    "    # Run FinBERT and get probabilities for all classes\n",
    "    all_scores = sentiment_nlp(text)[0]  # [{label: 'positive'|'negative'|'neutral', score: float}, ...]\n",
    "    score_map = {s[\"label\"].lower(): s[\"score\"] for s in all_scores}\n",
    "\n",
    "    pos = score_map.get(\"positive\", 0.0)\n",
    "    neg = score_map.get(\"negative\", 0.0)\n",
    "    neu = score_map.get(\"neutral\", 0.0)\n",
    "    polarity = pos - neg\n",
    "\n",
    "    rows.append({\n",
    "        \"date\": dt,\n",
    "        \"sentiment_pos\": pos,\n",
    "        \"sentiment_neg\": neg,\n",
    "        \"sentiment_neu\": neu,\n",
    "        \"sentiment_polarity\": polarity,\n",
    "    })\n",
    "\n",
    "article_df = pd.DataFrame(rows)\n",
    "print(f\"Scored {len(article_df)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969e5ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sentiment_polarity  sentiment_neg  sentiment_neu  sentiment_pos\n",
      "date                                                                       \n",
      "2026-01-02             0.06939         0.3179        0.29481        0.38729\n"
     ]
    }
   ],
   "source": [
    "# Aggregate to daily means to match backfill features\n",
    "if not article_df.empty:\n",
    "    article_df[\"date\"] = pd.to_datetime(article_df[\"date\"]).dt.normalize()\n",
    "    sentiment_daily = (\n",
    "        article_df.groupby(\"date\").agg({\n",
    "            \"sentiment_polarity\": \"mean\",\n",
    "            \"sentiment_neg\": \"mean\",\n",
    "            \"sentiment_neu\": \"mean\",\n",
    "            \"sentiment_pos\": \"mean\",\n",
    "        })\n",
    "    )\n",
    "    # Ensure timezone-naive index named 'date'\n",
    "    sentiment_daily.index = sentiment_daily.index.tz_localize(None)\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(sentiment_daily.head())\n",
    "else:\n",
    "    sentiment_daily = pd.DataFrame(\n",
    "        columns=[\"sentiment_polarity\", \"sentiment_neg\", \"sentiment_neu\", \"sentiment_pos\"]\n",
    "    )\n",
    "    sentiment_daily.index.name = \"date\"\n",
    "    print(\"No articles found for daily aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4673db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: sentiments_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/sentiments_2_offline_fg_materialization/executions\n",
      "2026-01-02 16:16:19,033 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2026-01-02 16:16:22,255 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-02 16:16:25,470 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-02 16:18:02,618 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-02 16:18:02,794 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-02 16:18:11,475 INFO: Execution finished successfully.\n",
      "Inserted daily sentiments into feature store\n"
     ]
    }
   ],
   "source": [
    "# Insert aggregated sentiments into Hopsworks Feature Store\n",
    "if sentiment_daily is not None and not sentiment_daily.empty:\n",
    "    df_to_insert = sentiment_daily.reset_index()\n",
    "    df_to_insert.columns = df_to_insert.columns.str.lower()\n",
    "\n",
    "    # Ensure feature group alignment with backfill\n",
    "    fg = fs.get_or_create_feature_group(\n",
    "        name=\"sentiments\",\n",
    "        description=\"AAPL stock sentiments\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    fg.insert(df_to_insert, wait=True)\n",
    "    print(\"Inserted daily sentiments into feature store\")\n",
    "else:\n",
    "    print(\"No sentiment data to insert today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2beb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.88s) \n",
      "Latest sentiment entries:\n",
      "                          date  sentiment_polarity  sentiment_neg  \\\n",
      "1578 2026-01-02 00:00:00+00:00            0.069390       0.317900   \n",
      "1577 2025-12-31 00:00:00+00:00            0.238841       0.181459   \n",
      "1576 2025-12-30 00:00:00+00:00            0.118052       0.183541   \n",
      "1    2025-12-29 00:00:00+00:00           -0.028438       0.218143   \n",
      "0    2025-12-23 00:00:00+00:00            0.298535       0.131626   \n",
      "\n",
      "      sentiment_neu  sentiment_pos  \n",
      "1578       0.294810       0.387290  \n",
      "1577       0.398241       0.420300  \n",
      "1576       0.514867       0.301592  \n",
      "1          0.592153       0.189705  \n",
      "0          0.438214       0.430160  \n",
      "\n",
      "Today's sentiment (2026-01-02):\n",
      "                          date  sentiment_polarity  sentiment_neg  \\\n",
      "1578 2026-01-02 00:00:00+00:00             0.06939         0.3179   \n",
      "\n",
      "      sentiment_neu  sentiment_pos  \n",
      "1578        0.29481        0.38729  \n"
     ]
    }
   ],
   "source": [
    "# Read all data from sentiments feature group\n",
    "sentiments_fg = fs.get_feature_group(\"sentiments\", version=2)\n",
    "sentiments_df = sentiments_fg.read()\n",
    "\n",
    "# Sort by date and show the most recent entries\n",
    "latest = sentiments_df.sort_values('date', ascending=False).head(5)\n",
    "print(\"Latest sentiment entries:\")\n",
    "print(latest)\n",
    "\n",
    "# Verify today's date is present\n",
    "today = pd.Timestamp.utcnow().normalize()\n",
    "today_data = sentiments_df[sentiments_df['date'] == today]\n",
    "print(f\"\\nToday's sentiment ({today.date()}):\")\n",
    "print(today_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a7e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert today's stock price into Hopsworks Feature Store\n",
    "# if not price.empty:\n",
    "#     # Prepare stock data to match backfill format\n",
    "#     stock_today = price[['Open']].copy()\n",
    "    \n",
    "#     # Remove timezone and normalize to date only\n",
    "#     stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "#     stock_today.index.name = 'date'\n",
    "    \n",
    "#     # Reset index to get date as column and lowercase column names\n",
    "#     stock_insert = stock_today.reset_index()\n",
    "#     stock_insert.columns = stock_insert.columns.str.lower()\n",
    "    \n",
    "#     print(\"Stock data to insert:\")\n",
    "#     print(stock_insert)\n",
    "    \n",
    "#     # Get or create the feature group (should already exist from backfill)\n",
    "#     opening_fg = fs.get_or_create_feature_group(\n",
    "#         name=\"opening_prices\",\n",
    "#         description=\"AAPL opening prices\",\n",
    "#         version=1,\n",
    "#         primary_key=[\"date\"],\n",
    "#         event_time=\"date\",\n",
    "#     )\n",
    "#     opening_fg.insert(stock_insert, wait=True)\n",
    "#     print(\"Inserted today's opening price into feature store\")\n",
    "# else:\n",
    "#     print(\"No stock price data available for today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f92a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2026-01-02 00:00:00-05:00  272.049988  277.824799  271.950012  275.200012   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits  \n",
      "Date                                                         \n",
      "2026-01-02 00:00:00-05:00  8891473        0.0           0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%3|1767367097.787|FAIL|rdkafka#consumer-4| [thrd:ssl://51.161.81.188:9093/1]: ssl://51.161.81.188:9093/1: SSL handshake failed: Disconnected: connection reset by peer: connecting to a PLAINTEXT broker listener? (after 117ms in state SSL_HANDSHAKE)\n",
      "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: opening_prices_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1267871/jobs/named/opening_prices_2_offline_fg_materialization/executions\n",
      "2026-01-02 16:18:32,795 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2026-01-02 16:18:36,048 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-02 16:18:39,268 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-02 16:20:19,592 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-02 16:20:19,768 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-02 16:20:28,451 INFO: Execution finished successfully.\n",
      "Inserted today's opening price (with target_open NA) into feature store\n",
      "        date        open  target_open\n",
      "0 2026-01-02  272.049988          NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(price)\n",
    "\n",
    "# Insert today's stock price into opening_prices v2 (with placeholder target)\n",
    "if not price.empty:\n",
    "    # Refresh feature store connection to avoid timeouts\n",
    "    fs = project.get_feature_store(\"A1ID2223\")\n",
    "    \n",
    "    stock_today = price[[\"Open\"]].copy()\n",
    "    stock_today.index = stock_today.index.tz_convert(None).normalize()\n",
    "    stock_today.index.name = 'date'\n",
    "\n",
    "    stock_insert = stock_today.reset_index()\n",
    "    stock_insert.columns = stock_insert.columns.str.lower()  # ['date','open']\n",
    "\n",
    "    # Match FG schema: include target_open as unknown for today\n",
    "    # Use np.nan instead of pd.NA for better compatibility with float columns\n",
    "    stock_insert['target_open'] = np.nan\n",
    "\n",
    "    opening_fg = fs.get_or_create_feature_group(\n",
    "        name=\"opening_prices\",\n",
    "        description=\"AAPL opening prices with next-day target\",\n",
    "        version=2,\n",
    "        primary_key=[\"date\"],\n",
    "        event_time=\"date\",\n",
    "    )\n",
    "    opening_fg.insert(stock_insert, wait=True)\n",
    "    print(\"Inserted today's opening price (with target_open NA) into feature store\")\n",
    "    print(stock_insert)\n",
    "else:\n",
    "    print(\"No stock price data available for today\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
